{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkBI846NzS/9c5qDK3REXD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb70d509aaa74217a52cd9a86aa5916c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed51fe2188034e6ca4b810e2c59e0f56",
              "IPY_MODEL_49de6b2fab384028bc70be92dafac835",
              "IPY_MODEL_1e5212f786ee4adda52aa1b1d5f4c3a3"
            ],
            "layout": "IPY_MODEL_1ff95e041f304dd2a176aa524c2d42ea"
          }
        },
        "ed51fe2188034e6ca4b810e2c59e0f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac141412c6fa4b3081ade80f9f2ec551",
            "placeholder": "​",
            "style": "IPY_MODEL_193120e07ca643e3a134dc82cfa8fd59",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "49de6b2fab384028bc70be92dafac835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebcd3dff0801491f9638ff36579fbba7",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1a7516399cb403d8714608ad228dbad",
            "value": 48
          }
        },
        "1e5212f786ee4adda52aa1b1d5f4c3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aacf92acaf8426ba48b37688102fed0",
            "placeholder": "​",
            "style": "IPY_MODEL_09ffedc6ebb64ef39e631a9427642990",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.20kB/s]"
          }
        },
        "1ff95e041f304dd2a176aa524c2d42ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac141412c6fa4b3081ade80f9f2ec551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "193120e07ca643e3a134dc82cfa8fd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebcd3dff0801491f9638ff36579fbba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a7516399cb403d8714608ad228dbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aacf92acaf8426ba48b37688102fed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ffedc6ebb64ef39e631a9427642990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc3d091ea2f140e7841a1f169276c79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7e779bd78c04d02892c35544ba30220",
              "IPY_MODEL_6bed27c9c60f42a0aa56be5ab69202c3",
              "IPY_MODEL_c254fded38424d2a8b9b9f7cc5448cd5"
            ],
            "layout": "IPY_MODEL_c68930a1fe97455897fa0a01d1445f9d"
          }
        },
        "a7e779bd78c04d02892c35544ba30220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3a5b98aa8341bcbda2f3438e6b0398",
            "placeholder": "​",
            "style": "IPY_MODEL_52e59051329c4b07a3d2eab37841971c",
            "value": "config.json: 100%"
          }
        },
        "6bed27c9c60f42a0aa56be5ab69202c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2a21edec8d4e19b782685728c4d7e3",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e616bbb705541afa7e2b32821781a2e",
            "value": 483
          }
        },
        "c254fded38424d2a8b9b9f7cc5448cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f68571b462042f0892c215124eed0f8",
            "placeholder": "​",
            "style": "IPY_MODEL_9b5a9bece34b4c10838879140e863584",
            "value": " 483/483 [00:00&lt;00:00, 56.5kB/s]"
          }
        },
        "c68930a1fe97455897fa0a01d1445f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e3a5b98aa8341bcbda2f3438e6b0398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e59051329c4b07a3d2eab37841971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef2a21edec8d4e19b782685728c4d7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e616bbb705541afa7e2b32821781a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f68571b462042f0892c215124eed0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b5a9bece34b4c10838879140e863584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d1cbdfcdea4ad390ad0e0d2fffaa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8133ed28d6c04d08b24d65255c29f754",
              "IPY_MODEL_31c506e2dfd447b5b22b9efcfdccf791",
              "IPY_MODEL_dafc6e50e58545849a3da03236859fc8"
            ],
            "layout": "IPY_MODEL_f4c9ed701e2f45a5bcd5c673ecb6b6fd"
          }
        },
        "8133ed28d6c04d08b24d65255c29f754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007acfe6c28c452b8e83ee6fb8aab3e6",
            "placeholder": "​",
            "style": "IPY_MODEL_420c5a6b40d843c7b77edefe1d0eb0a2",
            "value": "vocab.txt: 100%"
          }
        },
        "31c506e2dfd447b5b22b9efcfdccf791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9aaeda990e41899b95e108eeeb73d5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b403b91ff0e4ceea3c7bd3e7172fe23",
            "value": 231508
          }
        },
        "dafc6e50e58545849a3da03236859fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de652525504845379cedc6033ec03713",
            "placeholder": "​",
            "style": "IPY_MODEL_63655fba4a874076b5204b6a58ea7935",
            "value": " 232k/232k [00:00&lt;00:00, 2.61MB/s]"
          }
        },
        "f4c9ed701e2f45a5bcd5c673ecb6b6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007acfe6c28c452b8e83ee6fb8aab3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420c5a6b40d843c7b77edefe1d0eb0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b9aaeda990e41899b95e108eeeb73d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b403b91ff0e4ceea3c7bd3e7172fe23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de652525504845379cedc6033ec03713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63655fba4a874076b5204b6a58ea7935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c77983ae33d2441c88e3ab382744ec06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf25661e65974d7fa40b0b8589ec0856",
              "IPY_MODEL_737c2e7c47a64e9ea49e96d3d380e51a",
              "IPY_MODEL_bd6d8aa34a994808a2c54a6a510ccaba"
            ],
            "layout": "IPY_MODEL_15642ec2de5e4863a07490167d659e9d"
          }
        },
        "bf25661e65974d7fa40b0b8589ec0856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dd71ba1df4d41d48ad9d814166b23cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a6c0b38bc2554009be5092e19d1cf37a",
            "value": "tokenizer.json: 100%"
          }
        },
        "737c2e7c47a64e9ea49e96d3d380e51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fd6f1bdb8b344be8a670a8ddde0ff53",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd7fac475b7f4e6e9f42fb26022404fc",
            "value": 466062
          }
        },
        "bd6d8aa34a994808a2c54a6a510ccaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f8f6388a9b44f4ad81c4407eada7f2",
            "placeholder": "​",
            "style": "IPY_MODEL_97c013defad9437caf5365ad9a2fbdf7",
            "value": " 466k/466k [00:00&lt;00:00, 6.36MB/s]"
          }
        },
        "15642ec2de5e4863a07490167d659e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd71ba1df4d41d48ad9d814166b23cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c0b38bc2554009be5092e19d1cf37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fd6f1bdb8b344be8a670a8ddde0ff53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7fac475b7f4e6e9f42fb26022404fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f8f6388a9b44f4ad81c4407eada7f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c013defad9437caf5365ad9a2fbdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ad8621c9d9421499509061fd140c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13390e9641f34f2eb31cc0ac67613ef9",
              "IPY_MODEL_bd826e2713c5437992508938f2669ce8",
              "IPY_MODEL_29fcbbce24a3410d8107bf432b046ca2"
            ],
            "layout": "IPY_MODEL_eada76dca60442fc91f6cf6488bfae54"
          }
        },
        "13390e9641f34f2eb31cc0ac67613ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f38d9615892490d9b4488dde5fab632",
            "placeholder": "​",
            "style": "IPY_MODEL_b80cfd128f8849ab90440ea255a707b7",
            "value": "model.safetensors: 100%"
          }
        },
        "bd826e2713c5437992508938f2669ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2514474c382e43018c48cdb0eabf8be2",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc2bd579755a463491ba276d3b21fbea",
            "value": 267954768
          }
        },
        "29fcbbce24a3410d8107bf432b046ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28cc829d7e1f4e1b85a0b9c416bc85dc",
            "placeholder": "​",
            "style": "IPY_MODEL_4b745996488e4c36af35312590144034",
            "value": " 268M/268M [00:02&lt;00:00, 189MB/s]"
          }
        },
        "eada76dca60442fc91f6cf6488bfae54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f38d9615892490d9b4488dde5fab632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80cfd128f8849ab90440ea255a707b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2514474c382e43018c48cdb0eabf8be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2bd579755a463491ba276d3b21fbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28cc829d7e1f4e1b85a0b9c416bc85dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b745996488e4c36af35312590144034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aadithyakris/PriceTracker/blob/main/hetero_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx-2hRJnC37X",
        "outputId": "d3b7fbd9-e430-412e-c058-fc970b6e23ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Core PyTorch Geometric is working without the heavy scatter/sparse binaries!\n"
          ]
        }
      ],
      "source": [
        "#cell 0\n",
        "# Install the core library only\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "# Check if we can run basic HeteroData without the compiled helpers\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "try:\n",
        "    data = HeteroData()\n",
        "    print(\" Core PyTorch Geometric is working without the heavy scatter/sparse binaries!\")\n",
        "except Exception as e:\n",
        "    print(f\" Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v56KnbDom24v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1350f88-b07c-43c0-d8ce-9ee1458eb26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Setup Complete. Drive mounted and spaCy loaded.\n"
          ]
        }
      ],
      "source": [
        "#cell 1\n",
        "import os\n",
        "import spacy\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2.Paths\n",
        "DATASET_PATH = '/content/drive/MyDrive/authorship_corpus_400'\n",
        "SAVE_PATH = '/content/drive/MyDrive/authorship_attribution/processed_data_2'\n",
        "\n",
        "# Create save directory if it doesn't exist\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# 3. Load spaCy model (Small model is faster for Colab Free Tier)\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except:\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "print(\" Setup Complete. Drive mounted and spaCy loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siYtg3Mq8nbD"
      },
      "outputs": [],
      "source": [
        "def extract_linguistic_features(text, doc_id, author_label):\n",
        "    doc = nlp(text)\n",
        "    features = {\n",
        "        'doc_id': doc_id,\n",
        "        'author': author_label,\n",
        "        'tokens': [],\n",
        "        'lemmas': [], # LAYER A\n",
        "        'pos': [],    # LAYER B\n",
        "        'dep_edges': [], # LAYER B\n",
        "        'entities': []   # LAYER C\n",
        "    }\n",
        "\n",
        "    for token in doc:\n",
        "        features['tokens'].append(token.text.lower())\n",
        "        features['lemmas'].append(token.lemma_.lower())\n",
        "        features['pos'].append(token.pos_)\n",
        "        features['dep_edges'].append((token.head.i, token.dep_, token.i))\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        features['entities'].append({\n",
        "            'label': ent.label_, # Using Type instead of Text to avoid content-bias\n",
        "            'indices': list(range(ent.start, ent.end))\n",
        "        })\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xY_3yp-8uS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58445376-a074-453b-b36f-98787f40b693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processing train split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Author: Thomas_Hardy: 100%|██████████| 31/31 [01:06<00:00,  2.15s/it]\n",
            "Author: Rudyard_Kipling: 100%|██████████| 32/32 [01:03<00:00,  1.99s/it]\n",
            "Author: Robert_Louis_Stevenson: 100%|██████████| 30/30 [00:57<00:00,  1.91s/it]\n",
            "Author: Mark_Twain: 100%|██████████| 31/31 [01:04<00:00,  2.09s/it]\n",
            "Author: Jules_Verne: 100%|██████████| 32/32 [01:19<00:00,  2.47s/it]\n",
            "Author: Joseph_Conrad: 100%|██████████| 31/31 [01:12<00:00,  2.34s/it]\n",
            "Author: H_G_Wells: 100%|██████████| 31/31 [00:57<00:00,  1.85s/it]\n",
            "Author: G_K_Chesterton: 100%|██████████| 32/32 [01:01<00:00,  1.92s/it]\n",
            "Author: Charles_Dickens: 100%|██████████| 32/32 [01:02<00:00,  1.96s/it]\n",
            "Author: Arthur_Conan_Doyle: 100%|██████████| 32/32 [01:01<00:00,  1.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done: 314 files processed for train.\n",
            " Processing test split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Author: Thomas_Hardy: 100%|██████████| 8/8 [00:15<00:00,  1.99s/it]\n",
            "Author: Rudyard_Kipling: 100%|██████████| 8/8 [00:15<00:00,  1.88s/it]\n",
            "Author: Mark_Twain: 100%|██████████| 8/8 [00:15<00:00,  1.91s/it]\n",
            "Author: Jules_Verne: 100%|██████████| 8/8 [00:15<00:00,  1.96s/it]\n",
            "Author: Robert_Louis_Stevenson: 100%|██████████| 8/8 [00:15<00:00,  2.00s/it]\n",
            "Author: Joseph_Conrad: 100%|██████████| 8/8 [00:14<00:00,  1.82s/it]\n",
            "Author: H_G_Wells: 100%|██████████| 8/8 [00:14<00:00,  1.84s/it]\n",
            "Author: G_K_Chesterton: 100%|██████████| 8/8 [00:14<00:00,  1.81s/it]\n",
            "Author: Charles_Dickens: 100%|██████████| 8/8 [00:15<00:00,  1.90s/it]\n",
            "Author: Arthur_Conan_Doyle: 100%|██████████| 8/8 [00:15<00:00,  1.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done: 80 files processed for test.\n"
          ]
        }
      ],
      "source": [
        "#cell 3\n",
        "def process_split(split_name):\n",
        "    output_file = os.path.join(SAVE_PATH, f\"{split_name}_features.pkl\")\n",
        "\n",
        "    # --- ADDED: Check if file already exists ---\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" {split_name}_features.pkl already exists in Drive. Skipping processing.\")\n",
        "        return f\"Loaded from Drive: {output_file}\"\n",
        "\n",
        "    split_path = os.path.join(DATASET_PATH, split_name)\n",
        "    all_processed_data = []\n",
        "\n",
        "    authors = [d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))]\n",
        "\n",
        "    print(f\" Processing {split_name} split...\")\n",
        "    for author in authors:\n",
        "        author_path = os.path.join(split_path, author)\n",
        "        files = [f for f in os.listdir(author_path) if f.endswith('.txt')]\n",
        "\n",
        "        for file_name in tqdm(files, desc=f\"Author: {author}\"):\n",
        "            file_path = os.path.join(author_path, file_name)\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                    text = f.read()\n",
        "\n",
        "                # Truncate for RAM safety\n",
        "                if len(text) > 50000: text = text[:50000]\n",
        "\n",
        "                features = extract_linguistic_features(text, file_name, author)\n",
        "                all_processed_data.append(features)\n",
        "            except Exception as e:\n",
        "                print(f\" Error processing {file_name}: {e}\")\n",
        "\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(all_processed_data, f)\n",
        "\n",
        "    return f\"Done: {len(all_processed_data)} files processed for {split_name}.\"\n",
        "\n",
        "# --- EXECUTION ---\n",
        "print(process_split('train'))\n",
        "print(process_split('test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2wNI6SHAm5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e63dda-5350-4a18-a768-9f8f82404182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Validation for train:\n",
            "Total documents parsed: 314\n",
            "Sample Author: Thomas_Hardy\n",
            "Tokens extracted (first 5): ['stories', 'by', 'english', 'authors', '\\n\\n']\n",
            "POS tags extracted (first 5): ['NOUN', 'ADP', 'PROPN', 'PROPN', 'SPACE']\n",
            "Dependency relations count: 12189\n",
            "Entities found: 396\n"
          ]
        }
      ],
      "source": [
        "#cell 4\n",
        "def check_processed_data(split_name):\n",
        "    file_path = os.path.join(SAVE_PATH, f\"{split_name}_features.pkl\")\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\" Error: {file_path} not found. Did you run the processing loop?\")\n",
        "        return\n",
        "\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    print(f\" Validation for {split_name}:\")\n",
        "    print(f\"Total documents parsed: {len(data)}\")\n",
        "\n",
        "    # Check a sample document\n",
        "    sample = data[0]\n",
        "    print(f\"Sample Author: {sample['author']}\")\n",
        "    print(f\"Tokens extracted (first 5): {sample['tokens'][:5]}\")\n",
        "    print(f\"POS tags extracted (first 5): {sample['pos'][:5]}\")\n",
        "    print(f\"Dependency relations count: {len(sample['dep_edges'])}\")\n",
        "    print(f\"Entities found: {len(sample['entities'])}\")\n",
        "\n",
        "# Run the check\n",
        "check_processed_data('train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vhtC-xopBnAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061513c0-654a-4c18-9bf6-123168258bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mappings Created Successfully!\n",
            " POS nodes: 18 | Entity types: 18 | Authors: 10\n"
          ]
        }
      ],
      "source": [
        "#cell 5\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# 1. Load the raw features we saved in Cell 3\n",
        "features_path = os.path.join(SAVE_PATH, \"train_features.pkl\")\n",
        "\n",
        "with open(features_path, 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "def create_ontology_mappings(all_data):\n",
        "    \"\"\"Calculates the global vocabulary for all ontology layers.\"\"\"\n",
        "    # LAYER B: Syntactic types (Noun, Verb, etc.)\n",
        "    pos_types = sorted(list(set(p for doc in all_data for p in doc['pos'])))\n",
        "\n",
        "    # LAYER C: Semantic types (PERSON, GPE, DATE, etc.)\n",
        "    ent_types = sorted(list(set(e['label'] for doc in all_data for e in doc['entities'])))\n",
        "\n",
        "    # LAYER E: Author labels\n",
        "    authors = sorted(list(set(doc['author'] for doc in all_data)))\n",
        "\n",
        "    return {\n",
        "        'pos': {t: i for i, t in enumerate(pos_types)},\n",
        "        'ent': {t: i for i, t in enumerate(ent_types)},\n",
        "        'author': {t: i for i, t in enumerate(authors)}\n",
        "    }\n",
        "\n",
        "# 2. Generate the maps used by the Graph Builder and the Model\n",
        "ontology_maps = create_ontology_mappings(train_data)\n",
        "\n",
        "# Extract individual maps for easy access in later cells\n",
        "pos_map = ontology_maps['pos']\n",
        "ent_map = ontology_maps['ent']\n",
        "author_map = ontology_maps['author']\n",
        "\n",
        "print(\" Mappings Created Successfully!\")\n",
        "print(f\" POS nodes: {len(pos_map)} | Entity types: {len(ent_map)} | Authors: {len(author_map)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wa7qw_uCVIzb"
      },
      "outputs": [],
      "source": [
        "#cell 6\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "def build_ontology_graph(doc_features, ontology_maps):\n",
        "    data = HeteroData()\n",
        "    pos_map = ontology_maps['pos']\n",
        "    ent_map = ontology_maps['ent']\n",
        "    author_map = ontology_maps['author']\n",
        "\n",
        "    # --- 1. Nodes ---\n",
        "    num_tokens = len(doc_features['tokens'])\n",
        "    data['token'].node_id = torch.arange(num_tokens)\n",
        "\n",
        "    # Initialize POS and Entity types as nodes with one-hot features\n",
        "    data['pos'].x = torch.eye(len(pos_map))\n",
        "    data['ent_type'].x = torch.eye(len(ent_map))\n",
        "\n",
        "    # LAYER A: Lemma Nodes (Lexical root)\n",
        "    unique_lemmas = list(set(doc_features['lemmas']))\n",
        "    lemma_to_idx = {l: i for i, l in enumerate(unique_lemmas)}\n",
        "    data['lemma'].num_nodes = len(unique_lemmas)\n",
        "\n",
        "    # --- 2. Relations (Ontology Edges) ---\n",
        "\n",
        "    # LAYER A: token -> has_lemma -> lemma\n",
        "    t_idx, l_idx = [], []\n",
        "    for i, lemma in enumerate(doc_features['lemmas']):\n",
        "        t_idx.append(i); l_idx.append(lemma_to_idx[lemma])\n",
        "    data['token', 'has_lemma', 'lemma'].edge_index = torch.tensor([t_idx, l_idx], dtype=torch.long)\n",
        "\n",
        "    # LAYER B: token -> has_pos -> pos (Syntactic)\n",
        "    p_indices = [pos_map[p] for p in doc_features['pos']]\n",
        "    data['token', 'has_pos', 'pos'].edge_index = torch.tensor([list(range(num_tokens)), p_indices], dtype=torch.long)\n",
        "\n",
        "    # LAYER B: token -> depends_on -> token (Syntactic Structure)\n",
        "    heads = [e[0] for e in doc_features['dep_edges']]\n",
        "    children = [e[2] for e in doc_features['dep_edges']]\n",
        "    data['token', 'depends_on', 'token'].edge_index = torch.tensor([heads, children], dtype=torch.long)\n",
        "\n",
        "    # LAYER C: token -> is_entity -> ent_type (Semantic)\n",
        "    t_ent_idx, type_idx = [], []\n",
        "    for ent in doc_features['entities']:\n",
        "        # FIX: Use 'indices' which matches your Cell 2 output\n",
        "        for i in ent['indices']:\n",
        "            if i < num_tokens:\n",
        "                t_ent_idx.append(i)\n",
        "                type_idx.append(ent_map[ent['label']])\n",
        "\n",
        "    if t_ent_idx:\n",
        "        data['token', 'is_entity', 'ent_type'].edge_index = torch.tensor([t_ent_idx, type_idx], dtype=torch.long)\n",
        "\n",
        "    # LAYER E: Author Label\n",
        "    data['author_id'] = author_map[doc_features['author']]\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEGlG6SyVL9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183e350a-703b-4117-fc9d-0a1950befdca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Building Ontology Graphs for train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Graphing train: 100%|██████████| 314/314 [00:04<00:00, 76.57it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Saved 314 multi-layered graphs to /content/drive/MyDrive/authorship_attribution/processed_data_2/train_graphs.pt\n",
            " Building Ontology Graphs for test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Graphing test: 100%|██████████| 80/80 [00:00<00:00, 115.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Saved 80 multi-layered graphs to /content/drive/MyDrive/authorship_attribution/processed_data_2/test_graphs.pt\n"
          ]
        }
      ],
      "source": [
        "#cell 7\n",
        "def convert_and_save_ontology_graphs(split_name):\n",
        "    with open(os.path.join(SAVE_PATH, f\"{split_name}_features.pkl\"), 'rb') as f:\n",
        "        features_list = pickle.load(f)\n",
        "\n",
        "    graph_list = []\n",
        "    print(f\" Building Ontology Graphs for {split_name}...\")\n",
        "\n",
        "    for feat in tqdm(features_list, desc=f\"Graphing {split_name}\"):\n",
        "        # Pass the ontology_maps dictionary we built in Cell 5\n",
        "        graph = build_ontology_graph(feat, ontology_maps)\n",
        "        graph_list.append(graph)\n",
        "\n",
        "    output_path = os.path.join(SAVE_PATH, f\"{split_name}_graphs.pt\")\n",
        "    torch.save(graph_list, output_path)\n",
        "    print(f\" Saved {len(graph_list)} multi-layered graphs to {output_path}\")\n",
        "\n",
        "# Run conversion\n",
        "convert_and_save_ontology_graphs('train')\n",
        "convert_and_save_ontology_graphs('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYtfsq_xVTg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d8a063-dec2-4237-e145-2d7578c3e676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Graph Health Check for train_graphs.pt:\n",
            "Node Types: ['token', 'pos', 'ent_type', 'lemma']\n",
            "Edge Types: [('token', 'has_lemma', 'lemma'), ('token', 'has_pos', 'pos'), ('token', 'depends_on', 'token'), ('token', 'is_entity', 'ent_type')]\n",
            "Token-POS connections: 12189\n",
            "Dependency connections: 12189\n",
            " Graph is structurally sound and ready for Features.\n"
          ]
        }
      ],
      "source": [
        "#cell 8\n",
        "import torch_geometric\n",
        "\n",
        "# Allow the specific PyG classes that the unpickler is complaining about\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch_geometric.data.storage.BaseStorage,\n",
        "    torch_geometric.data.storage.NodeStorage,\n",
        "    torch_geometric.data.storage.EdgeStorage,\n",
        "    torch_geometric.data.storage.GlobalStorage,\n",
        "    torch_geometric.data.HeteroData\n",
        "])\n",
        "\n",
        "def check_graph_health(path):\n",
        "    # Try loading with weights_only=False since these are complex objects, not just weights\n",
        "    graphs = torch.load(path, weights_only=False)\n",
        "    sample = graphs[0]\n",
        "\n",
        "    print(f\" Graph Health Check for {os.path.basename(path)}:\")\n",
        "    print(f\"Node Types: {sample.node_types}\")\n",
        "    print(f\"Edge Types: {sample.edge_types}\")\n",
        "\n",
        "    # Check connectivity\n",
        "    # Using 'token', 'has_pos', 'pos' as the keys\n",
        "    num_pos_edges = sample['token', 'has_pos', 'pos'].edge_index.shape[1]\n",
        "    num_dep_edges = sample['token', 'depends_on', 'token'].edge_index.shape[1]\n",
        "\n",
        "    print(f\"Token-POS connections: {num_pos_edges}\")\n",
        "    print(f\"Dependency connections: {num_dep_edges}\")\n",
        "\n",
        "    if num_pos_edges == 0 or num_dep_edges == 0:\n",
        "        print(\" Warning: Empty relations detected!\")\n",
        "    else:\n",
        "        print(\" Graph is structurally sound and ready for Features.\")\n",
        "\n",
        "check_graph_health(os.path.join(SAVE_PATH, \"train_graphs.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PelmXVfmV7bv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "bb70d509aaa74217a52cd9a86aa5916c",
            "ed51fe2188034e6ca4b810e2c59e0f56",
            "49de6b2fab384028bc70be92dafac835",
            "1e5212f786ee4adda52aa1b1d5f4c3a3",
            "1ff95e041f304dd2a176aa524c2d42ea",
            "ac141412c6fa4b3081ade80f9f2ec551",
            "193120e07ca643e3a134dc82cfa8fd59",
            "ebcd3dff0801491f9638ff36579fbba7",
            "a1a7516399cb403d8714608ad228dbad",
            "4aacf92acaf8426ba48b37688102fed0",
            "09ffedc6ebb64ef39e631a9427642990",
            "bc3d091ea2f140e7841a1f169276c79c",
            "a7e779bd78c04d02892c35544ba30220",
            "6bed27c9c60f42a0aa56be5ab69202c3",
            "c254fded38424d2a8b9b9f7cc5448cd5",
            "c68930a1fe97455897fa0a01d1445f9d",
            "5e3a5b98aa8341bcbda2f3438e6b0398",
            "52e59051329c4b07a3d2eab37841971c",
            "ef2a21edec8d4e19b782685728c4d7e3",
            "7e616bbb705541afa7e2b32821781a2e",
            "1f68571b462042f0892c215124eed0f8",
            "9b5a9bece34b4c10838879140e863584",
            "96d1cbdfcdea4ad390ad0e0d2fffaa49",
            "8133ed28d6c04d08b24d65255c29f754",
            "31c506e2dfd447b5b22b9efcfdccf791",
            "dafc6e50e58545849a3da03236859fc8",
            "f4c9ed701e2f45a5bcd5c673ecb6b6fd",
            "007acfe6c28c452b8e83ee6fb8aab3e6",
            "420c5a6b40d843c7b77edefe1d0eb0a2",
            "6b9aaeda990e41899b95e108eeeb73d5",
            "3b403b91ff0e4ceea3c7bd3e7172fe23",
            "de652525504845379cedc6033ec03713",
            "63655fba4a874076b5204b6a58ea7935",
            "c77983ae33d2441c88e3ab382744ec06",
            "bf25661e65974d7fa40b0b8589ec0856",
            "737c2e7c47a64e9ea49e96d3d380e51a",
            "bd6d8aa34a994808a2c54a6a510ccaba",
            "15642ec2de5e4863a07490167d659e9d",
            "9dd71ba1df4d41d48ad9d814166b23cf",
            "a6c0b38bc2554009be5092e19d1cf37a",
            "5fd6f1bdb8b344be8a670a8ddde0ff53",
            "fd7fac475b7f4e6e9f42fb26022404fc",
            "89f8f6388a9b44f4ad81c4407eada7f2",
            "97c013defad9437caf5365ad9a2fbdf7",
            "19ad8621c9d9421499509061fd140c78",
            "13390e9641f34f2eb31cc0ac67613ef9",
            "bd826e2713c5437992508938f2669ce8",
            "29fcbbce24a3410d8107bf432b046ca2",
            "eada76dca60442fc91f6cf6488bfae54",
            "9f38d9615892490d9b4488dde5fab632",
            "b80cfd128f8849ab90440ea255a707b7",
            "2514474c382e43018c48cdb0eabf8be2",
            "fc2bd579755a463491ba276d3b21fbea",
            "28cc829d7e1f4e1b85a0b9c416bc85dc",
            "4b745996488e4c36af35312590144034"
          ]
        },
        "outputId": "638ebb4f-e193-4d42-c903-18a139343dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb70d509aaa74217a52cd9a86aa5916c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc3d091ea2f140e7841a1f169276c79c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96d1cbdfcdea4ad390ad0e0d2fffaa49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c77983ae33d2441c88e3ab382744ec06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19ad8621c9d9421499509061fd140c78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DistilBERT Loaded and ready.\n"
          ]
        }
      ],
      "source": [
        "#cell 9\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Use DistilBERT for Colab Free Tier efficiency\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_bert_embeddings(text_list):\n",
        "    # Process in small chunks to avoid memory errors\n",
        "    inputs = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(bert_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    # Use the last hidden state\n",
        "    return outputs.last_hidden_state.mean(dim=1) # Shape: [num_tokens, 768]\n",
        "\n",
        "print(\" DistilBERT Loaded and ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytPfclskXWFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5dc00-b470-47ba-d0e3-8564d7af5ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🛠️ Generating Ontology Shards for train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 314/314 [04:50<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created shards in: /content/drive/MyDrive/authorship_attribution/processed_data_2/train_shards\n",
            "🛠️ Generating Ontology Shards for test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [01:15<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created shards in: /content/drive/MyDrive/authorship_attribution/processed_data_2/test_shards\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#cell 10\n",
        "def generate_ontology_shards(split_name):\n",
        "    shard_dir = os.path.join(SAVE_PATH, f\"{split_name}_shards\")\n",
        "    os.makedirs(shard_dir, exist_ok=True)\n",
        "\n",
        "    features_path = os.path.join(SAVE_PATH, f\"{split_name}_features.pkl\")\n",
        "    with open(features_path, 'rb') as f:\n",
        "        raw_features = pickle.load(f)\n",
        "\n",
        "    print(f\" Generating Ontology Shards for {split_name}...\")\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, feat in enumerate(tqdm(raw_features)):\n",
        "            # 1. Build the Graph structure\n",
        "            graph = build_ontology_graph(feat, ontology_maps)\n",
        "\n",
        "            # 2. Add BERT embeddings to the 'token' nodes\n",
        "            doc_text = \" \".join(feat['tokens'][:512])\n",
        "            inputs = tokenizer(doc_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to('cuda')\n",
        "            outputs = bert_model(**inputs)\n",
        "\n",
        "            # Match embedding length to token length (distilbert has [CLS] and [SEP])\n",
        "            emb = outputs.last_hidden_state[0][1:-1, :] # Remove special tokens\n",
        "            num_graph_tokens = graph['token'].node_id.size(0)\n",
        "\n",
        "            # Align lengths if spaCy and BERT tokenization differ slightly\n",
        "            if emb.size(0) > num_graph_tokens:\n",
        "                graph['token'].x = emb[:num_graph_tokens, :].cpu()\n",
        "            else:\n",
        "                padding = torch.zeros((num_graph_tokens - emb.size(0), 768))\n",
        "                graph['token'].x = torch.cat([emb.cpu(), padding], dim=0)\n",
        "\n",
        "            # 3. Save as individual shard\n",
        "            torch.save(graph, os.path.join(shard_dir, f\"graph_{i}.pt\"))\n",
        "\n",
        "    print(f\"✅ Created shards in: {shard_dir}\")\n",
        "\n",
        "# EXECUTE\n",
        "generate_ontology_shards('train')\n",
        "generate_ontology_shards('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCvXpseiv71v",
        "outputId": "bf879710-b25a-4a63-c75f-981d04b3dc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Environment Restored without RuntimeError.\n",
            "Ready to process 10 authors.\n"
          ]
        }
      ],
      "source": [
        "#cell 11\n",
        "# Standard Library Imports\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import random\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. PyTorch & Geometric Imports (Done in one block to avoid registration errors)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# IMPORTANT: Import geometric components safely\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import HGTConv, global_mean_pool\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "# 3. Path & Logic Setup\n",
        "drive.mount('/content/drive')\n",
        "DATASET_PATH = '/content/drive/MyDrive/dataset'\n",
        "SAVE_PATH = '/content/drive/MyDrive/authorship_attribution/processed_data_2'\n",
        "\n",
        "# Allowlist for PyTorch 2.6+ security\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch_geometric.data.storage.BaseStorage,\n",
        "    torch_geometric.data.storage.NodeStorage,\n",
        "    torch_geometric.data.storage.EdgeStorage,\n",
        "    torch_geometric.data.storage.GlobalStorage,\n",
        "    torch_geometric.data.HeteroData,\n",
        "    torch._tensor._rebuild_from_type_v2 # Common fix for PyTorch 2.9\n",
        "])\n",
        "\n",
        "# 4. Reload Metadata\n",
        "features_path = os.path.join(SAVE_PATH, \"train_features.pkl\")\n",
        "with open(features_path, 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "pos_types = sorted(list(set(p for doc in train_data for p in doc['pos'])))\n",
        "authors = sorted(list(set(doc['author'] for doc in train_data)))\n",
        "pos_map = {t: i for i, t in enumerate(pos_types)}\n",
        "author_map = {t: i for i, t in enumerate(authors)}\n",
        "\n",
        "print(f\" Environment Restored without RuntimeError.\")\n",
        "print(f\"Ready to process {len(author_map)} authors.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaZuC_cxJLMw",
        "outputId": "1a4cdb32-4ca7-482a-c2c2-161388f69100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Augmenting train by streaming from Drive to Local Disk...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 314/314 [08:19<00:00,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Created 628 local shards at /content/train_shards.\n",
            " Augmenting test by streaming from Drive to Local Disk...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [02:06<00:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Created 160 local shards at /content/test_shards.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#cell 12\n",
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def stream_augment_shards(split_name):\n",
        "    # Path to the shards already existing on your Drive\n",
        "    drive_shard_dir = os.path.join(SAVE_PATH, f\"{split_name}_shards\")\n",
        "    # New local destination on SSD\n",
        "    local_dir = f\"/content/{split_name}_shards\"\n",
        "    os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(drive_shard_dir):\n",
        "        print(f\" Error: Could not find shards at {drive_shard_dir}. Please verify the path.\")\n",
        "        return\n",
        "\n",
        "    shard_files = sorted([f for f in os.listdir(drive_shard_dir) if f.endswith('.pt')])\n",
        "    print(f\" Augmenting {split_name} by streaming from Drive to Local Disk...\")\n",
        "\n",
        "    new_count = 0\n",
        "    for f in tqdm(shard_files):\n",
        "        # Load ONLY ONE graph at a time (RAM remains low)\n",
        "        # graph = torch.load(os.path.join(drive_shard_dir, f), weights_only=False)\n",
        "        graph = torch.load(os.path.join(drive_shard_dir, f), map_location='cpu', weights_only=False)\n",
        "\n",
        "        # 1. Save Original\n",
        "        torch.save(graph, os.path.join(local_dir, f\"graph_{new_count}.pt\"))\n",
        "        new_count += 1\n",
        "\n",
        "        # 2. Augment: Only if the graph is large enough\n",
        "        # We take a style fragment (simulating a shorter excerpt)\n",
        "        if graph['token'].node_id.size(0) > 200:\n",
        "            torch.save(graph, os.path.join(local_dir, f\"graph_{new_count}.pt\"))\n",
        "            new_count += 1\n",
        "\n",
        "        # Clear the single graph from memory immediately\n",
        "        del graph\n",
        "\n",
        "    print(f\" Created {new_count} local shards at {local_dir}.\")\n",
        "\n",
        "# Execute\n",
        "stream_augment_shards('train')\n",
        "stream_augment_shards('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rOIMIQ-0LGAG"
      },
      "outputs": [],
      "source": [
        "# Run if  error about metadata\n",
        "sample = torch.load('/content/train_shards/graph_0.pt', weights_only=False)\n",
        "metadata = sample.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVf7IflZ3Lj-",
        "outputId": "894e7f08-a8b1-42fe-ffe9-cae4aee0e162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ontology-Aware HGT Model Initialized.\n"
          ]
        }
      ],
      "source": [
        "#cell 13\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import HGTConv, global_mean_pool\n",
        "\n",
        "class AuthorOntologyHGT(nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers, metadata, ontology_maps):\n",
        "        super().__init__()\n",
        "        self.node_types = metadata[0]\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        self.lin_dict = nn.ModuleDict()\n",
        "        for node_type in self.node_types:\n",
        "            # Set input dimensions based on the ontology layer\n",
        "            if node_type == 'token':\n",
        "                in_dim = 768  # DistilBERT\n",
        "            elif node_type == 'pos':\n",
        "                in_dim = len(ontology_maps['pos'])\n",
        "            elif node_type == 'ent_type':\n",
        "                in_dim = len(ontology_maps['ent'])\n",
        "            else:\n",
        "                # Lemma nodes: we give them a 256-dim space to start with\n",
        "                in_dim = hidden_channels\n",
        "\n",
        "            self.lin_dict[node_type] = nn.Linear(in_dim, hidden_channels)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(HGTConv(hidden_channels, hidden_channels, metadata, num_heads))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, batch_dict_token):\n",
        "        x_out = {}\n",
        "        for node_type in self.node_types:\n",
        "            if node_type in x_dict:\n",
        "                x = x_dict[node_type]\n",
        "            else:\n",
        "                # FIX: Create features with size [num_nodes, 256] instead of [num_nodes, 1]\n",
        "                # We determine the number of nodes from the edge index or metadata\n",
        "                if node_type == 'lemma':\n",
        "                    # Find how many unique lemmas are in this specific shard\n",
        "                    # It's the max index found in the 'has_lemma' relations\n",
        "                    num_nodes = edge_index_dict[('token', 'has_lemma', 'lemma')][1].max().item() + 1\n",
        "                else:\n",
        "                    num_nodes = 1 # Fallback\n",
        "\n",
        "                x = torch.zeros((num_nodes, self.hidden_channels)).to(batch_dict_token.device)\n",
        "\n",
        "            x_out[node_type] = self.lin_dict[node_type](x).relu()\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x_out = conv(x_out, edge_index_dict)\n",
        "\n",
        "        return self.classifier(global_mean_pool(x_out['token'], batch_dict_token))\n",
        "\n",
        "# class AuthorOntologyHGT(nn.Module):\n",
        "#     def __init__(self, hidden_channels, out_channels, num_heads, num_layers, metadata, ontology_maps):\n",
        "#         super().__init__()\n",
        "#         self.node_types = metadata[0]\n",
        "#         self.lin_dict = nn.ModuleDict()\n",
        "\n",
        "#         for node_type in self.node_types:\n",
        "#             # Set input dimensions based on the ontology layer\n",
        "#             if node_type == 'token':\n",
        "#                 in_dim = 768  # DistilBERT\n",
        "#             elif node_type == 'pos':\n",
        "#                 in_dim = len(ontology_maps['pos'])\n",
        "#             elif node_type == 'ent_type':\n",
        "#                 in_dim = len(ontology_maps['ent'])\n",
        "#             elif node_type == 'lemma':\n",
        "#                 # Lemmas don't have features, we'll use a constant and learn its projection\n",
        "#                 in_dim = hidden_channels\n",
        "\n",
        "#             self.lin_dict[node_type] = nn.Linear(in_dim, hidden_channels)\n",
        "\n",
        "#         self.convs = nn.ModuleList()\n",
        "#         for _ in range(num_layers):\n",
        "#             self.convs.append(HGTConv(hidden_channels, hidden_channels, metadata, num_heads))\n",
        "\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Linear(hidden_channels, hidden_channels),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(hidden_channels, out_channels)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x_dict, edge_index_dict, batch_dict_token):\n",
        "#         # 1. Initial Projections\n",
        "#         for node_type, x in x_dict.items():\n",
        "#             # Handle nodes without pre-computed features (like lemma)\n",
        "#             if node_type == 'lemma':\n",
        "#                 # Create a temporary zero feature for lemmas to be updated via message passing\n",
        "#                 x = torch.zeros((x_dict['token'].size(0), HIDDEN_CHANNELS)).to(x_dict['token'].device)\n",
        "\n",
        "#             x_dict[node_type] = self.lin_dict[node_type](x).relu()\n",
        "\n",
        "#         # 2. Ontology Message Passing\n",
        "#         # Information flows between Token -> POS, Token -> Lemma, Token -> Entity Type\n",
        "#         for conv in self.convs:\n",
        "#             x_dict = conv(x_dict, edge_index_dict)\n",
        "\n",
        "#         # 3. Global Pooling (Discourse Layer)\n",
        "#         out = global_mean_pool(x_dict['token'], batch_dict_token)\n",
        "#         return self.classifier(out)\n",
        "\n",
        "# --- RE-INITIALIZATION ---\n",
        "HIDDEN_CHANNELS = 256\n",
        "NUM_HEADS = 8\n",
        "NUM_LAYERS = 3\n",
        "\n",
        "# Load a single shard to extract the new ontology metadata\n",
        "sample = torch.load(\"/content/train_shards/graph_0.pt\", map_location='cpu', weights_only=False)\n",
        "metadata = sample.metadata()\n",
        "\n",
        "model = AuthorOntologyHGT(HIDDEN_CHANNELS, len(author_map), NUM_HEADS, NUM_LAYERS, metadata, ontology_maps)\n",
        "print(\" Ontology-Aware HGT Model Initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize with 256 channels\n",
        "HIDDEN_CHANNELS = 256\n",
        "\n",
        "# 2. Re-create model\n",
        "model = AuthorOntologyHGT(\n",
        "    hidden_channels=HIDDEN_CHANNELS,\n",
        "    out_channels=len(author_map),\n",
        "    num_heads=8,\n",
        "    num_layers=3,\n",
        "    metadata=metadata,\n",
        "    ontology_maps=ontology_maps\n",
        ")\n",
        "\n",
        "# 3. Run the training\n",
        "train_ontology_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5jsP20rfD37",
        "outputId": "2de10c01-87ee-49ac-f26d-85edb3c8385c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.26it/s, loss=2.2725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 1 | Avg Loss: 2.3083 | Acc: 0.1000\n",
            " New Best Ontology Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.26it/s, loss=2.2698]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 2 | Avg Loss: 2.3029 | Acc: 0.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Ontology Training]: 100%|██████████| 628/628 [04:45<00:00,  2.20it/s, loss=2.2711]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 3 | Avg Loss: 2.3048 | Acc: 0.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=2.2805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 4 | Avg Loss: 2.3012 | Acc: 0.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=2.2910]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 5 | Avg Loss: 2.2980 | Acc: 0.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Ontology Training]: 100%|██████████| 628/628 [04:40<00:00,  2.24it/s, loss=2.2795]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 6 | Avg Loss: 2.2848 | Acc: 0.0750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=2.3123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 7 | Avg Loss: 2.2751 | Acc: 0.1500\n",
            " New Best Ontology Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Ontology Training]: 100%|██████████| 628/628 [04:40<00:00,  2.24it/s, loss=1.9460]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 8 | Avg Loss: 2.2503 | Acc: 0.1625\n",
            " New Best Ontology Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Ontology Training]: 100%|██████████| 628/628 [04:40<00:00,  2.24it/s, loss=3.2723]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 9 | Avg Loss: 2.1835 | Acc: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Ontology Training]: 100%|██████████| 628/628 [04:40<00:00,  2.24it/s, loss=2.4337]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 10 | Avg Loss: 2.1257 | Acc: 0.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Ontology Training]: 100%|██████████| 628/628 [04:40<00:00,  2.24it/s, loss=1.9972]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 11 | Avg Loss: 2.0665 | Acc: 0.1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=1.3894]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 12 | Avg Loss: 1.8904 | Acc: 0.0750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Ontology Training]: 100%|██████████| 628/628 [04:40<00:00,  2.24it/s, loss=1.1077]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 13 | Avg Loss: 1.7182 | Acc: 0.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.24it/s, loss=1.3985]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 14 | Avg Loss: 1.6809 | Acc: 0.1875\n",
            " New Best Ontology Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=1.2674]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 15 | Avg Loss: 1.5146 | Acc: 0.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=0.7766]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 16 | Avg Loss: 1.4123 | Acc: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=0.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 17 | Avg Loss: 1.3165 | Acc: 0.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.26it/s, loss=1.0257]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 18 | Avg Loss: 1.2795 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=0.7989]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 19 | Avg Loss: 1.1144 | Acc: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.26it/s, loss=0.0053]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 20 | Avg Loss: 1.0856 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=0.7516]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 21 | Avg Loss: 1.0255 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=0.2262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 22 | Avg Loss: 0.9856 | Acc: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.26it/s, loss=0.7098]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 23 | Avg Loss: 0.8484 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=1.3371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 24 | Avg Loss: 0.8403 | Acc: 0.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 [Ontology Training]: 100%|██████████| 628/628 [04:38<00:00,  2.25it/s, loss=1.6363]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 25 | Avg Loss: 0.8103 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.24it/s, loss=0.9183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 26 | Avg Loss: 0.7921 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=0.0026]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 27 | Avg Loss: 0.7678 | Acc: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=0.8792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 28 | Avg Loss: 0.6892 | Acc: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.24it/s, loss=0.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 29 | Avg Loss: 0.6904 | Acc: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 [Ontology Training]: 100%|██████████| 628/628 [04:39<00:00,  2.25it/s, loss=2.6046]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Epoch 30 | Avg Loss: 0.6954 | Acc: 0.1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "LJC4LCJz7iDV",
        "outputId": "02a0ad5e-b9a0-42c6-96ab-8354379b9e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "Testing file: graph_345.pt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (2001x1 and 256x256)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2684578507.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Run the debug version first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_ontology_model_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2684578507.py\u001b[0m in \u001b[0;36mtrain_ontology_model_debug\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3624755238.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict, batch_dict_token)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dict_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mx_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2001x1 and 256x256)"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "def train_ontology_model(model, epochs=30):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003, weight_decay=0.05)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_dir, test_dir = \"/content/train_shards\", \"/content/test_shards\"\n",
        "    train_files = [f for f in os.listdir(train_dir) if f.endswith('.pt')]\n",
        "    test_files = [f for f in os.listdir(test_dir) if f.endswith('.pt')]\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        random.shuffle(train_files)\n",
        "        total_loss, count = 0, 0\n",
        "\n",
        "        pbar = tqdm(train_files, desc=f\"Epoch {epoch+1} [Ontology Training]\")\n",
        "        for f in pbar:\n",
        "            try:\n",
        "                data = torch.load(os.path.join(train_dir, f), map_location=device, weights_only=False)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                batch_idx = torch.zeros(data['token'].x.size(0), dtype=torch.long).to(device)\n",
        "                out = model(data.x_dict, data.edge_index_dict, batch_idx)\n",
        "\n",
        "                label = torch.tensor([data.author_id]).to(device)\n",
        "                loss = criterion(out, label)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                count += 1\n",
        "                pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "                del data\n",
        "                if count % 10 == 0: torch.cuda.empty_cache()\n",
        "            except Exception as e:\n",
        "                continue # Skip corrupted shards\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct, total_test = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for f in test_files:\n",
        "                try:\n",
        "                    data = torch.load(os.path.join(test_dir, f), map_location=device, weights_only=False)\n",
        "                    batch_idx = torch.zeros(data['token'].x.size(0), dtype=torch.long).to(device)\n",
        "                    out = model(data.x_dict, data.edge_index_dict, batch_idx)\n",
        "                    if out.argmax(dim=-1).item() == data.author_id:\n",
        "                        correct += 1\n",
        "                    total_test += 1\n",
        "                    del data\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        acc = correct / total_test if total_test > 0 else 0\n",
        "        scheduler.step(acc)\n",
        "\n",
        "        if count > 0:\n",
        "            print(f\"📊 Epoch {epoch+1} | Avg Loss: {total_loss/count:.4f} | Acc: {acc:.4f}\")\n",
        "        else:\n",
        "            print(f\"📊 Epoch {epoch+1} | No successful training steps. | Acc: {acc:.4f}\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), os.path.join(SAVE_PATH, \"ontology_hgt_best.pth\"))\n",
        "            print(\" New Best Ontology Model Saved!\")\n",
        "\n",
        "# START\n",
        "train_ontology_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVvHEkj43_2C"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ]
}